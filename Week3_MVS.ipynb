{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGI84rsSoYvC"
   },
   "source": [
    "# Week 3: Multiview Reconstruction\n",
    "\n",
    "# Week 2: Stereo Estimation\n",
    "\n",
    "If you are working in Colab,\n",
    "*   Open Files from left\n",
    "*   Drag and drop `Week3_MVS.zip` there (or click upload icon on top left). Upload can take a few minutes.\n",
    "*   Unzip the file by running the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reJ9VBXSkpJT"
   },
   "outputs": [],
   "source": [
    "!unzip Week3_MVS.zip\n",
    "%cd Week3_MVS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xd-UcIY3kqBs"
   },
   "source": [
    "*   If you get disconnected from the runtime, you might need to upload this file again. Also, note that this is valid for other local files too eg. repos that have been cloned, files generated during execution etc. In short, if you see that your files are gone after a while, just run the cell that generates, clones, etc. the missing files again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgZC0Entx1tj"
   },
   "source": [
    "## Part A: More on Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMhF53abyFsC"
   },
   "source": [
    "### Question 1: Transformations\n",
    "\n",
    "Derive the matrices $M \\in SE(3) \\subset \\mathbb{R}^{4 \\times 4}$ representing the following transformations:\n",
    "\n",
    "* Translation by the vector $T \\in \\mathbb{R}^3$\n",
    "* Rotation by the rotation matrix $R \\in \\mathbb{R}^{3 \\times 3}$\n",
    "* Rotation by $R$ followed by the translation $T$\n",
    "* Translation by $T$ followed by the rotation $R$\n",
    "\n",
    "**Hint:** Remember that we can write the transformation matrix $M$ for a given rotation matrix\n",
    "$R = \\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13} \\\\\n",
    "r_{21} & r_{22} & r_{23} \\\\\n",
    "r_{31} & r_{32} & r_{33}\n",
    "\\end{bmatrix}$ and a translation vector $T = \\begin{bmatrix}\n",
    "t_x \\\\\n",
    "t_y \\\\\n",
    "t_z\n",
    "\\end{bmatrix}$ as follows:\n",
    "$M = \n",
    "\\begin{pmatrix}\n",
    "R & T \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13} & t_x \\\\\n",
    "r_{21} & r_{22} & r_{23} & t_y \\\\\n",
    "r_{31} & r_{32} & r_{33} & t_z \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7fcS5m14h0x"
   },
   "source": [
    "### Question 2: Scale Ambiguity\n",
    "\n",
    "A classic ambiguity of the perspective projection is that one cannot tell an object from another object that is exactly twice as big but twice as far. Explain why this is true.\n",
    "\n",
    "**Hint:** Let $P = (X, Y, Z)$ be a point on the smaller object and $P' = (X', Y', Z')$ a point on the larger object. Define $X' = 2X, Y' = 2Y, Z' = 2Z$ and perpective projection as a function $p = \\pi(P)$. How does $\\pi$ transform the world coordinate $P$ to image coordinate $p$ according to perspective projection? Repeat the same for $P'$ and $p'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3Fsiel_hgHs"
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGhT5gFM4CaK"
   },
   "source": [
    "## Part B: Rotating Objects\n",
    "\n",
    "Write a function that rotates the model around its center (i.e. the mean of its vertices) for given rotation angles $\\alpha,~\\beta,~\\gamma$ around the x-, y- and z-axis. Use homogeneous coordinates and describe the overall transformation by a single matrix. \n",
    "\n",
    "The rotation matrices around the respective axes are as follows:\n",
    "\n",
    "$R_x = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & \\text{cos}~\\alpha & -\\text{sin}~\\alpha \\\\\n",
    "0 & \\text{sin}~\\alpha & \\text{cos}~\\alpha\n",
    "\\end{bmatrix}\n",
    "~~~%\n",
    "R_y = \\begin{bmatrix}\n",
    "\\text{cos}~\\beta & 0 & \\text{sin}~\\beta \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "-\\text{sin}~\\beta & 0 & \\text{cos}~\\beta\n",
    "\\end{bmatrix}\n",
    "~~~%\n",
    "R_z = \\begin{bmatrix}\n",
    "\\text{cos}~\\gamma & -\\text{sin}~\\gamma & 0 \\\\\n",
    "\\text{sin}~\\gamma & \\text{cos}~\\gamma & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Rotate the model first 50 degrees around the x-axis and then 25 degrees around the z-axis. Now start again by doing the same rotation around the z-axis first followed by the x-axis rotation. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLfV61JF4G6d"
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def deg2rad(angleInDegrees):\n",
    "    angleInRadians = (np.pi/180) * angleInDegrees\n",
    "    return angleInRadians\n",
    "\n",
    "def rotation(V, alpha_degree, beta_degree, gamma_degree, order):\n",
    "\n",
    "    # Compute mean of vertices for vertex list V \n",
    "    center = None\n",
    "    \n",
    "    #Create a translation matrix T as a 4x4 matrix that translates the model to the point (0,0,0) \n",
    "    T = None\n",
    "    \n",
    "    #Create a translation matrix T_back as a 4x4 matrix that translates back to the center of V\n",
    "    T_back = None\n",
    "    \n",
    "    # convert degrees to radians\n",
    "    alpha, beta, gamma = None, None, None\n",
    "    \n",
    "    # Rotation matrices in homegeneuous coordinate\n",
    "    R_x = None\n",
    "    R_y = None\n",
    "    R_z = None\n",
    "    \n",
    "    # Calculate Overall transformation matrix G (using T, T_back, R_x, R_y, R_z, order)\n",
    "    # order determines the order of applying the rotations. \n",
    "    # e.g. if order=='xyz' first rotate around the x axis, then around y axis and then around the z axis\n",
    "    G = None\n",
    "            \n",
    "    # Homogeneous coordinates of V\n",
    "    Vh = None\n",
    "    \n",
    "    # Apply the transformation to the vertices (using G and Vh)\n",
    "    Wh = None\n",
    "    # Go back from homogenous  to 3D coordinates\n",
    "    W = None\n",
    "    return W\n",
    "         \n",
    "# load the model\n",
    "mesh = o3d.io.read_triangle_mesh(\"data/model.off\")\n",
    "V = np.asarray(mesh.vertices)\n",
    "\n",
    "# display the model\n",
    "mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "# rotate the model (first around the x axis)\n",
    "W = rotation(V, 50, 0, 25, order='xyz')\n",
    "rotated_mesh = o3d.geometry.TriangleMesh(vertices=o3d.utility.Vector3dVector(W), triangles=mesh.triangles)\n",
    "\n",
    "# display the rotated model\n",
    "rotated_mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([rotated_mesh])\n",
    "\n",
    "# rotate the model (first around the z axis)\n",
    "W = rotation(V, 50, 0, 25, order='zyx')\n",
    "rotated_mesh = o3d.geometry.TriangleMesh(vertices=o3d.utility.Vector3dVector(W), triangles=mesh.triangles)\n",
    "\n",
    "# display the rotated model\n",
    "rotated_mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([rotated_mesh])\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: pykitti\n",
    "\n",
    "There is a nice repository which serves as a development kit for KITTI in python: [pykitti](https://github.com/utiasSTARS/pykitti)\n",
    "\n",
    "Install it and repeat the steps below with the provided sequence to see what kind of properties of the dataset is available with pykitti. After that, you will compute stereo as you did last week, this time by using pykitti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opAAxRLI4HDt"
   },
   "outputs": [],
   "source": [
    "import pykitti\n",
    "import numpy as np\n",
    "\n",
    "basedir = 'data/KITTI-Raw'\n",
    "date = '2011_09_26'\n",
    "drive = '0079'\n",
    "\n",
    "# The 'frames' argument is optional - default: None, which loads the whole dataset.\n",
    "# Calibration, timestamps, and IMU data are read automatically. \n",
    "# Camera and velodyne data are available via properties that create generators\n",
    "# when accessed, or through getter methods that provide random access.\n",
    "dataset = pykitti.raw(basedir, date, drive, frames=range(0, 50, 5))\n",
    "\n",
    "# dataset.calib:         Calibration data are accessible as a named tuple\n",
    "# dataset.timestamps:    Timestamps are parsed into a list of datetime objects\n",
    "# dataset.oxts:          List of OXTS packets and 6-dof poses as named tuples\n",
    "# dataset.camN:          Returns a generator that loads individual images from camera N\n",
    "# dataset.get_camN(idx): Returns the image from camera N at idx  \n",
    "# dataset.gray:          Returns a generator that loads monochrome stereo pairs (cam0, cam1)\n",
    "# dataset.get_gray(idx): Returns the monochrome stereo pair at idx  \n",
    "# dataset.rgb:           Returns a generator that loads RGB stereo pairs (cam2, cam3)\n",
    "# dataset.get_rgb(idx):  Returns the RGB stereo pair at idx  \n",
    "# dataset.velo:          Returns a generator that loads velodyne scans as [x,y,z,reflectance]\n",
    "# dataset.get_velo(idx): Returns the velodyne scan at idx  \n",
    "\n",
    "# Get the following data:\n",
    "\n",
    "#Length of the loaded dataset\n",
    "len_dataset = None\n",
    "\n",
    "#Gray stereo pair baseline\n",
    "gray_baseline = None\n",
    "\n",
    "#RGB stereo pair baseline\n",
    "rgb_baseline = None\n",
    "\n",
    "#Difference between the first and the second timestamp\n",
    "diff_timestamp = None\n",
    "\n",
    "#Last gray image (left camera)\n",
    "last_gray_left = None\n",
    "\n",
    "#Last gray image (right camera)\n",
    "last_gray_right = None\n",
    "\n",
    "#Last rgb image (left camera)\n",
    "last_rgb_left = None\n",
    "\n",
    "#Last rgb image (right camera)\n",
    "last_rgb_right = None\n",
    "\n",
    "#Third velodyne scan\n",
    "third_velo = None\n",
    "\n",
    "print('\\nLength of the loaded dataset: ' + str(len_dataset))\n",
    "print('\\nGray stereo pair baseline [m]: ' + str(gray_baseline))\n",
    "print('\\nRGB stereo pair baseline [m]: ' + str(rgb_baseline))\n",
    "print('\\nDifference between Gray and RGB baselines: [m]', abs(rgb_baseline - gray_baseline))\n",
    "\n",
    "print('\\nDifference beteween the first and the second timestamp: ' + str(diff_timestamp))\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
    "ax[0, 0].imshow(last_gray_left, cmap='gray')\n",
    "ax[0, 0].set_title('Last Gray Image (Left)')\n",
    "\n",
    "ax[0, 1].imshow(last_gray_right, cmap='gray')\n",
    "ax[0, 1].set_title('Last Gray Image (Right)')\n",
    "\n",
    "ax[1, 0].imshow(last_rgb_left)\n",
    "ax[1, 0].set_title('Last RGB Image (Left)')\n",
    "\n",
    "ax[1, 1].imshow(last_rgb_right)\n",
    "ax[1, 1].set_title('Right RGB Image (Right)')\n",
    "\n",
    "\n",
    "f2 = plt.figure()\n",
    "ax2 = f2.add_subplot(111, projection='3d')\n",
    "# Plot every 100th point so things don't get too bogged down\n",
    "velo_range = range(0, third_velo.shape[0], 100)\n",
    "ax2.scatter(third_velo[velo_range, 0],\n",
    "            third_velo[velo_range, 1],\n",
    "            third_velo[velo_range, 2],\n",
    "            c=third_velo[velo_range, 3],\n",
    "            cmap='gray')\n",
    "ax2.set_title('Third Velodyne scan (subsampled)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do stereo processing \n",
    "# Use last_gray_left and last_gray_right and calculate the disparity\n",
    "disp_gray = None\n",
    "\n",
    "# Use last_rgb_left and last_rgb_right and calculate the disparity\n",
    "disp_rgb = None\n",
    "\n",
    "# Display some data\n",
    "f, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
    "ax[0, 0].imshow(last_gray_left, cmap='gray')\n",
    "ax[0, 0].set_title('Left Gray Image (cam0)')\n",
    "\n",
    "ax[0, 1].imshow(disp_gray, cmap='viridis')\n",
    "ax[0, 1].set_title('Gray Stereo Disparity')\n",
    "\n",
    "ax[1, 0].imshow(last_rgb_left)\n",
    "ax[1, 0].set_title('Left RGB Image (cam2)')\n",
    "\n",
    "ax[1, 1].imshow(disp_rgb, cmap='viridis')\n",
    "ax[1, 1].set_title('RGB Stereo Disparity')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week_2_Object_Detection_Extended_Assignments.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
