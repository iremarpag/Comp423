{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Week_2_Object_Detection_Extended_Assignments.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iremarpag/Comp423/blob/main/Week_3_Object_Detection_Extended_Assignments_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGI84rsSoYvC"
      },
      "source": [
        "# Week 3: Multiview Reconstruction\n",
        "\n",
        "# Week 2: Stereo Estimation\n",
        "\n",
        "If you are working in Colab,\n",
        "*   Open Files from left\n",
        "*   Drag and drop `Week3_MVS.zip` there (or click upload icon on top left). Upload can take a few minutes.\n",
        "*   Unzip the file by running the following cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJ9VBXSkpJT"
      },
      "source": [
        "!unzip Week3_MVS.zip\n",
        "%cd Week3_MVS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd-UcIY3kqBs"
      },
      "source": [
        "*   If you get disconnected from the runtime, you might need to upload this file again. Also, note that this is valid for other local files too eg. repos that have been cloned, files generated during execution etc. In short, if you see that your files are gone after a while, just run the cell that generates, clones, etc. the missing files again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgZC0Entx1tj"
      },
      "source": [
        "## Part A: More on Projections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMhF53abyFsC"
      },
      "source": [
        "### Question 1: Transformations\n",
        "\n",
        "Derive the matrices $M \\in SE(3) \\subset \\mathbb{R}^{4 \\times 4}$ representing the following transformations:\n",
        "\n",
        "* Translation by the vector $T \\in \\mathbb{R}^3$\n",
        "* Rotation by the rotation matrix $R \\in \\mathbb{R}^{3 \\times 3}$\n",
        "* Rotation by $R$ followed by the translation $T$\n",
        "* Translation by $T$ followed by the rotation $R$\n",
        "\n",
        "**Hint:** Remember that we can write the transformation matrix $M$ for a given rotation matrix\n",
        "$R = \\begin{bmatrix}\n",
        "r_{11} & r_{12} & r_{13} \\\\\n",
        "r_{21} & r_{22} & r_{23} \\\\\n",
        "r_{31} & r_{32} & r_{33}\n",
        "\\end{bmatrix}$ and a translation vector $T = \\begin{bmatrix}\n",
        "t_x \\\\\n",
        "t_y \\\\\n",
        "t_z\n",
        "\\end{bmatrix}$ as follows:\n",
        "$M = \n",
        "\\begin{pmatrix}\n",
        "R & T \\\\\n",
        "0 & 1\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "r_{11} & r_{12} & r_{13} & t_x \\\\\n",
        "r_{21} & r_{22} & r_{23} & t_y \\\\\n",
        "r_{31} & r_{32} & r_{33} & t_z \\\\\n",
        "0 & 0 & 0 & 1 \\\\\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc5FR3Ekq5zP"
      },
      "source": [
        "**Answer**:⊤ be the translation vector. Then a point p is transformed\r\n",
        "into\r\n",
        "p\r\n",
        "′ = R(p − p0\r\n",
        ") + p0 + b.\r\n",
        "It turns out that the rotation part of a rigid body transformation does not depend on the reference\r\n",
        "point chosen. Suppose that a different point q0 has been chosen as the reference point. Then we\r\n",
        "rewrite\r\n",
        "p\r\n",
        "′ = R(p − q0 + q0 − p0\r\n",
        ") + p0 + b\r\n",
        "= R(p − q0\r\n",
        ") + q0 + c,\r\n",
        "where c = R(q0 − p0\r\n",
        ") + p0 − q0 + b is the new translation vector.\r\n",
        "The same transformation from p to p\r\n",
        "′\r\n",
        "can also be regarded as a translation followed by a\r\n",
        "rotation, for we have\r\n",
        "p\r\n",
        "′ = R(p − p0 + R\r\n",
        "−1\r\n",
        "b)\r\n",
        "= R(p + e − r)\r\n",
        "\r\n",
        "a rotation in the space takes about a line referred to as its rotation\r\n",
        "axis. Any rotation can be decomposed into three primary rotations about the x-, and y-, and\r\n",
        "z-axes:\r\n",
        "Rotx(θx) =\r\n",
        "1 0 0 0\r\n",
        "0 cos θx − sin θx 0\r\n",
        "0 sin θx cos θx 0\r\n",
        "0 0 0 1,\r\n",
        "Roty(θy) =\r\n",
        "cos θy 0 sin θy 0\r\n",
        "0 1 0 0\r\n",
        "− sin θy 0 cos θy 0\r\n",
        "0 0 0 1,\r\n",
        "Rotz(θz) =\r\n",
        "cos θz − sin θz 0 0\r\n",
        "sin θz cos θz 0 0\r\n",
        "0 0 1 0\r\n",
        "0 0 0 1.\r\n",
        "8\r\n",
        "Figure 4(a) shows the direction in which the primary rotations take when the rotation angle\r\n",
        "is positive. Figure 4(b) is a mnemonic that helps to remember the directions. For instance, the\r\n",
        "x\r\n",
        "z\r\n",
        "y\r\n",
        "θx\r\n",
        "θy\r\n",
        "θz x\r\n",
        "y z\r\n",
        "(a) (b)\r\n",
        "Figure 4: Rotations about the coordinate axes.\r\n",
        "positive sense of a rotation about the y-axis has the effect of moving points on the z-axis toward\r\n",
        "the x-axis.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7fcS5m14h0x"
      },
      "source": [
        "### Question 2: Scale Ambiguity\n",
        "\n",
        "A classic ambiguity of the perspective projection is that one cannot tell an object from another object that is exactly twice as big but twice as far. Explain why this is true.\n",
        "\n",
        "**Hint:** Let $P = (X, Y, Z)$ be a point on the smaller object and $P' = (X', Y', Z')$ a point on the larger object. Define $X' = 2X, Y' = 2Y, Z' = 2Z$ and perpective projection as a function $p = \\pi(P)$. How does $\\pi$ transform the world coordinate $P$ to image coordinate $p$ according to perspective projection? Repeat the same for $P'$ and $p'$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Fsiel_hgHs"
      },
      "source": [
        "**Answer**: The scene point P is observed at points PI and Pr in the\r\n",
        "left and right image planes, respectively. Without loss of generality, let us\r\n",
        "11.1. STEREO IMAGING 291\r\n",
        "assume that the origin of the coordinate system coincides with the left lens\r\n",
        "center. Comparing the similar triangles P MCI and PILCI, we get\r\n",
        "Similarly, from the similar triangles P NCr and PrRCr, we get\r\n",
        "x - b x'\r\n",
        "- = -'!:\r\n",
        "z f\r\n",
        "Combining these two equations, we get\r\n",
        "bf\r\n",
        "z= (x~- x~)\r\n",
        "Thus, the depth at various scene points may be recovered by knowing the\r\n",
        "disparities of corresponding image points.\r\n",
        "Note that due to the discrete nature of the digital images, the disparity\r\n",
        "values are integers unless special algorithms are used to compute disparities to\r\n",
        "sub pixel accuracy. Thus, for a given set of camera parameters, the accuracy\r\n",
        "of depth computation for a given scene point is enhanced by increasing the\r\n",
        "baseline distance b so that the corresponding disparity is large. Such wideangle stereopsis methods introduce other problems, however. For instance,\r\n",
        "when the baseline distance is increased, the fraction of all scene points that\r\n",
        "are seen by both cameras decreases. Furthermore, even those regions that are\r\n",
        "seen by both cameras are likely to appear different in one image compared to\r\n",
        "the corresponding regions in the other image due to distortions introduced\r\n",
        "by perspective projection, making it difficult to identify conjugate pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGhT5gFM4CaK"
      },
      "source": [
        "## Part B: Rotating Objects\n",
        "\n",
        "Write a function that rotates the model around its center (i.e. the mean of its vertices) for given rotation angles $\\alpha,~\\beta,~\\gamma$ around the x-, y- and z-axis. Use homogeneous coordinates and describe the overall transformation by a single matrix. \n",
        "\n",
        "The rotation matrices around the respective axes are as follows:\n",
        "\n",
        "$R_x = \\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & \\text{cos}~\\alpha & -\\text{sin}~\\alpha \\\\\n",
        "0 & \\text{sin}~\\alpha & \\text{cos}~\\alpha\n",
        "\\end{bmatrix}\n",
        "~~~%\n",
        "R_y = \\begin{bmatrix}\n",
        "\\text{cos}~\\beta & 0 & \\text{sin}~\\beta \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "-\\text{sin}~\\beta & 0 & \\text{cos}~\\beta\n",
        "\\end{bmatrix}\n",
        "~~~%\n",
        "R_z = \\begin{bmatrix}\n",
        "\\text{cos}~\\gamma & -\\text{sin}~\\gamma & 0 \\\\\n",
        "\\text{sin}~\\gamma & \\text{cos}~\\gamma & 0 \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "Rotate the model first 50 degrees around the x-axis and then 25 degrees around the z-axis. Now start again by doing the same rotation around the z-axis first followed by the x-axis rotation. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLfV61JF4G6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "86a73183-b6f7-4491-ec19-fc9a55840830"
      },
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "def deg2rad(angleInDegrees):\n",
        "    angleInRadians = (np.pi/180) * angleInDegrees\n",
        "    return angleInRadians\n",
        "\n",
        "def rotation(V, alpha_degree, beta_degree, gamma_degree, order):\n",
        "\n",
        "    # Compute mean of vertices for vertex list V \n",
        "    center = wm * v.co\n",
        "    \n",
        "    #Create a translation matrix T as a 4x4 matrix that translates the model to the point (0,0,0) \n",
        "   data['T_cam0_velo'] = np.reshape(filedata['Tr'], (3, 4))\n",
        "        data['T_cam0_velo'] = np.vstack([data['T_cam0_velo'], [0, 0, 0, 1]])\n",
        "    \n",
        "    #Create a translation matrix T_back as a 4x4 matrix that translates back to the center of V\n",
        "     self._df = self._df[self._df['occluded'] >= occluded_threshold[0]]\n",
        "     self._df = self._df[self._df['occluded'] <= occluded_threshold[1]]\n",
        "\n",
        "    # convert degrees to radians\n",
        "    alpha, beta, gamma = 0.123, -1.234, 2.345\n",
        "    \n",
        "    # Rotation matrices in homegeneuous coordinate\n",
        "      data['T_cam1_velo'] = T1.dot(data['T_cam0_velo'])\n",
        "      data['T_cam2_velo'] = T2.dot(data['T_cam0_velo'])\n",
        "      data['T_cam3_velo'] = T3.dot(data['T_cam0_velo'])\n",
        "    \n",
        "    # Calculate Overall transformation matrix G (using T, T_back, R_x, R_y, R_z, order)\n",
        "    # order determines the order of applying the rotations. \n",
        "    # e.g. if order=='xyz' first rotate around the x axis, then around y axis and then around the z axis\n",
        "    G = R = euler_matrix(1, 2, 3, 'syxz')\n",
        "   numpy.allclose(numpy.sum(R[0]), -1.34786452)\n",
        "\n",
        "            \n",
        "    # Homogeneous coordinates of V\n",
        "    Vh = quaternion_matrix([0.06146124, 0, 0, 0.99810947])\n",
        "   numpy.allclose(R, rotation_matrix(0.123, (1, 0, 0)))\n",
        "\n",
        "    \n",
        "    # Apply the transformation to the vertices (using G and Vh)\n",
        "    local_coords = np.zeros(len(my_obj.data.vertices) * 3) \n",
        "    my_obj.data.vertices.foreach_get('co', local_coords)\n",
        "\n",
        "    # Go back from homogenous  to 3D coordinates\n",
        "    ai, aj, ak = (4.0*math.pi) * (numpy.random.random(3) - 0.5)\n",
        "    for axes in _AXES2TUPLE.keys():\n",
        "     W = euler_matrix(ai, aj, ak, axes)\n",
        "    for axes in _TUPLE2AXES.keys():\n",
        "     W = euler_matrix(ai, aj, ak, axes)\n",
        "    return W\n",
        "         \n",
        "# load the model\n",
        "mesh = o3d.io.read_triangle_mesh(\"data/model.off\")\n",
        "V = np.asarray(mesh.vertices)\n",
        "\n",
        "# display the model\n",
        "mesh.compute_vertex_normals()\n",
        "o3d.visualization.draw_geometries([mesh])\n",
        "\n",
        "# rotate the model (first around the x axis)\n",
        "W = rotation(V, 50, 0, 25, order='xyz')\n",
        "rotated_mesh = o3d.geometry.TriangleMesh(vertices=o3d.utility.Vector3dVector(W), triangles=mesh.triangles)\n",
        "\n",
        "# display the rotated model\n",
        "rotated_mesh.compute_vertex_normals()\n",
        "o3d.visualization.draw_geometries([rotated_mesh])\n",
        "\n",
        "# rotate the model (first around the z axis)\n",
        "W = rotation(V, 50, 0, 25, order='zyx')\n",
        "rotated_mesh = o3d.geometry.TriangleMesh(vertices=o3d.utility.Vector3dVector(W), triangles=mesh.triangles)\n",
        "\n",
        "# display the rotated model\n",
        "rotated_mesh.compute_vertex_normals()\n",
        "o3d.visualization.draw_geometries([rotated_mesh])\n",
        "\n",
        "print('done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-167f05ef1839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopen3d\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mo3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeg2rad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangleInDegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mangleInRadians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mangleInDegrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'open3d'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPOXLz_5q5zX"
      },
      "source": [
        "## Part C: pykitti\n",
        "\n",
        "There is a nice repository which serves as a development kit for KITTI in python: [pykitti](https://github.com/utiasSTARS/pykitti)\n",
        "\n",
        "Install it and repeat the steps below with the provided sequence to see what kind of properties of the dataset is available with pykitti. After that, you will compute stereo as you did last week, this time by using pykitti."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opAAxRLI4HDt"
      },
      "source": [
        "import pykitti\n",
        "import numpy as np\n",
        "\n",
        "basedir = 'data/KITTI-Raw'\n",
        "date = '2011_09_26'\n",
        "drive = '0079'\n",
        "\n",
        "# The 'frames' argument is optional - default: None, which loads the whole dataset.\n",
        "# Calibration, timestamps, and IMU data are read automatically. \n",
        "# Camera and velodyne data are available via properties that create generators\n",
        "# when accessed, or through getter methods that provide random access.\n",
        "dataset = pykitti.raw(basedir, date, drive, frames=range(0, 50, 5))\n",
        "\n",
        "# dataset.calib:         Calibration data are accessible as a named tuple\n",
        "# dataset.timestamps:    Timestamps are parsed into a list of datetime objects\n",
        "# dataset.oxts:          List of OXTS packets and 6-dof poses as named tuples\n",
        "# dataset.camN:          Returns a generator that loads individual images from camera N\n",
        "# dataset.get_camN(idx): Returns the image from camera N at idx  \n",
        "# dataset.gray:          Returns a generator that loads monochrome stereo pairs (cam0, cam1)\n",
        "# dataset.get_gray(idx): Returns the monochrome stereo pair at idx  \n",
        "# dataset.rgb:           Returns a generator that loads RGB stereo pairs (cam2, cam3)\n",
        "# dataset.get_rgb(idx):  Returns the RGB stereo pair at idx  \n",
        "# dataset.velo:          Returns a generator that loads velodyne scans as [x,y,z,reflectance]\n",
        "# dataset.get_velo(idx): Returns the velodyne scan at idx  \n",
        "\n",
        "# Get the following data:\n",
        "\n",
        "def __len__(self):\n",
        "        return len(self.timestamps)\n",
        "#Length of the loaded dataset\n",
        "self._get_file_lists()\n",
        "        print('files', len(self.cam2_files))\n",
        "@property\n",
        "    def gray(self):\n",
        "        \"\"\"Generator to read monochrome stereo pairs from file.\n",
        "        \"\"\"\n",
        "        return zip(self.cam0, self.cam1)\n",
        "\n",
        "    def get_gray(self, idx):\n",
        "        \"\"\"Read monochrome stereo pair at the specified index.\"\"\"\n",
        "        return (self.get_cam0(idx), self.get_cam1(idx))\n",
        "#Gray stereo pair baseline\n",
        "\n",
        "\n",
        "#RGB stereo pair baseline\n",
        "@property\n",
        "    def rgb(self):\n",
        "        \"\"\"Generator to read RGB stereo pairs from file.\n",
        "        \"\"\"\n",
        "        return zip(self.cam2, self.cam3)\n",
        "\n",
        "    def get_rgb(self, idx):\n",
        "        \"\"\"Read RGB stereo pair at the specified index.\"\"\"\n",
        "        return (self.get_cam2(idx), self.get_cam3(idx))\n",
        "\n",
        "#Difference between the first and the second timestamp\n",
        "diff_timestamp = None\n",
        "\n",
        "#Last gray image (left camera)\n",
        "def gray(self):\n",
        "        \"\"\"Generator to read monochrome stereo pairs from file.\n",
        "        \"\"\"\n",
        "        return zip(self.cam0, self.cam1)\n",
        "\n",
        "#Last gray image (right camera)\n",
        "last_gray_right = None\n",
        "\n",
        "#Last rgb image (left camera)\n",
        " @property\n",
        "    def cam2(self):\n",
        "        \"\"\"Generator to read image files for cam2 (RGB left).\"\"\"\n",
        "        return utils.yield_images(self.cam2_files, mode='RGB')\n",
        "\n",
        "    def get_cam2(self, idx):\n",
        "        \"\"\"Read image file for cam2 (RGB left) at the specified index.\"\"\"\n",
        "        return utils.load_image(self.cam2_files[idx], mode='RGB')\n",
        "\n",
        "#Last rgb image (right camera)\n",
        "  @property\n",
        "    def cam3(self):\n",
        "        \"\"\"Generator to read image files for cam0 (RGB right).\"\"\"\n",
        "        return utils.yield_images(self.cam3_files, mode='RGB')\n",
        "\n",
        "    def get_cam3(self, idx):\n",
        "        \"\"\"Read image file for cam3 (RGB right) at the specified index.\"\"\"\n",
        "        return utils.load_image(self.cam3_files[idx], mode='RGB')\n",
        "\n",
        "#Third velodyne scan\n",
        "third_velo = self._load_calib_rigid(velo_to_cam_file)\n",
        "        data[third_velo] = T_cam0unrect_velo\n",
        "\n",
        "print('\\nLength of the loaded dataset: ' + str(len_dataset))\n",
        "print('\\nGray stereo pair baseline [m]: ' + str(gray_baseline))\n",
        "print('\\nRGB stereo pair baseline [m]: ' + str(rgb_baseline))\n",
        "print('\\nDifference between Gray and RGB baselines: [m]', abs(rgb_baseline - gray_baseline))\n",
        "\n",
        "print('\\nDifference beteween the first and the second timestamp: ' + str(diff_timestamp))\n",
        "\n",
        "\n",
        "f, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
        "ax[0, 0].imshow(last_gray_left, cmap='gray')\n",
        "ax[0, 0].set_title('Last Gray Image (Left)')\n",
        "\n",
        "ax[0, 1].imshow(last_gray_right, cmap='gray')\n",
        "ax[0, 1].set_title('Last Gray Image (Right)')\n",
        "\n",
        "ax[1, 0].imshow(last_rgb_left)\n",
        "ax[1, 0].set_title('Last RGB Image (Left)')\n",
        "\n",
        "ax[1, 1].imshow(last_rgb_right)\n",
        "ax[1, 1].set_title('Right RGB Image (Right)')\n",
        "\n",
        "\n",
        "f2 = plt.figure()\n",
        "ax2 = f2.add_subplot(111, projection='3d')\n",
        "# Plot every 100th point so things don't get too bogged down\n",
        "velo_range = range(0, third_velo.shape[0], 100)\n",
        "ax2.scatter(third_velo[velo_range, 0],\n",
        "            third_velo[velo_range, 1],\n",
        "            third_velo[velo_range, 2],\n",
        "            c=third_velo[velo_range, 3],\n",
        "            cmap='gray')\n",
        "ax2.set_title('Third Velodyne scan (subsampled)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8msum7Xq5zg"
      },
      "source": [
        "# Do stereo processing \n",
        "# Use last_gray_left and last_gray_right and calculate the disparity\n",
        "disp_gray =  np.linalg.norm(p_velo1 - p_velo0)\n",
        "\n",
        "# Use last_rgb_left and last_rgb_right and calculate the disparity\n",
        "disp_rgb = np.linalg.norm(p_velo3 - p_velo2)\n",
        "\n",
        "# Display some data\n",
        "f, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
        "ax[0, 0].imshow(last_gray_left, cmap='gray')\n",
        "ax[0, 0].set_title('Left Gray Image (cam0)')\n",
        "\n",
        "ax[0, 1].imshow(disp_gray, cmap='viridis')\n",
        "ax[0, 1].set_title('Gray Stereo Disparity')\n",
        "\n",
        "ax[1, 0].imshow(last_rgb_left)\n",
        "ax[1, 0].set_title('Left RGB Image (cam2)')\n",
        "\n",
        "ax[1, 1].imshow(disp_rgb, cmap='viridis')\n",
        "ax[1, 1].set_title('RGB Stereo Disparity')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}