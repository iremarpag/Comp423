{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "flownet3d.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iremarpag/Comp423/blob/main/flownet3d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oltMOCo4gkD0"
      },
      "source": [
        "# Week 4: Scene Flow Estimation\n",
        "\n",
        "If you are running on Colab,\n",
        "* Go to runtime -> change runtime type -> select \"GPU\" as the hardware accelerator. \n",
        "\n",
        "This week's assignment has two parts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffiRr-EEgkD9"
      },
      "source": [
        "## Part A\n",
        "\n",
        "In the first part, you'll annotate the code below for [FlowNet3D](https://arxiv.org/abs/1806.01411). What does it mean to annotate a notebook?\n",
        "\n",
        "The original implementation of FlowNet3D is in TensorFlow: [tf-code](https://github.com/xingyul/flownet3d). Someone has implemented it in PyTorch and provided the notebook below: [pytorch-code](https://github.com/multimodallearning/flownet3d.pytorch). This is great but the notebook is not very helpful for someone trying to match it to the paper.\n",
        "\n",
        "When it is done right, it looks like this: [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html). Can you provide a similar encapsulation for the code below by putting relevant parts of the paper before the code segment? Feel free to divide code segments further and copy text or figures from the paper but make sure that it matches the code and furthermore explains what is done in the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhoEmesfgkD-"
      },
      "source": [
        "## Part B\n",
        "\n",
        "In the second part, you will extend the code to KITTI. You can use the models pre-trained on FlyingThings3D in the `models` folder. For KITTI, please use the preprocessed data by removing ground from the original TensorFlow repo:\n",
        "\n",
        "\"We release the processed KITTI scene flow dataset [here](https://drive.google.com/open?id=1XBsF35wKY0rmaL7x7grD_evvKCAccbKi) for download (total size ~266MB). The KITTI scene flow dataset was processed by converting the 2D optical flow into 3D scene flow and removing the ground points. We processed the first 150 data points from KITTI scene flow dataset. Each of the data points are stored as a .npz file and its dictionary has three keys: pos1, pos2 and gt, representing the first frame of point cloud, second frame of point cloud and the ground truth scene flow vectors for the points in the first frame.\"\n",
        "\n",
        "**Question**: Using the model trained on FlyingThings3D and evaluating it on the pre-processed KITTI, can you reproduce the results in the last row of the Table 4? You will need to implement the 'outliers' metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyV62XoPgkD_"
      },
      "source": [
        "### Hints\n",
        "For running the code you will need to install kaolin v0.1.\n",
        "You can use the following lines to install Kaolin on Google Colab, or you can follow the [installation guide](https://kaolin.readthedocs.io/en/latest/notes/installation.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EJ8DLyDgkD_",
        "outputId": "dc5a407e-18d0-48c0-a822-e3ddced349bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone -b v0.1 https://github.com/NVIDIAGameWorks/kaolin.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kaolin'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 1904 (delta 15), reused 16 (delta 5), pack-reused 1846\u001b[K\n",
            "Receiving objects: 100% (1904/1904), 53.81 MiB | 4.10 MiB/s, done.\n",
            "Resolving deltas: 100% (937/937), done.\n",
            "Note: checking out 'c537bf76111153b83555787354b6f8f20d4d58a0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-nqV0nDgkEA",
        "outputId": "25b9b06d-2cc5-4db5-e138-3a7e9b43c17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "!pip install kaolin/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./kaolin\n",
            "Collecting matplotlib<3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/38/64d5579936b9058c39c443f186e3ee20c0a4bb0ccc9d3618a1be93b01d05/matplotlib-2.2.5-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 254kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image==0.16.2 in /usr/local/lib/python3.7/dist-packages (from kaolin==0.1.0) (0.16.2)\n",
            "Collecting trimesh>=3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/a702771ce5f3914a17c85994fdb369f826b6c3973404add51bd6f77db0ca/trimesh-3.9.9-py3-none-any.whl (629kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from kaolin==0.1.0) (1.4.1)\n",
            "Collecting tqdm==4.32.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/af/685bf3ce889ea191f3b916557f5677cc95a5e87b2fa120d74b5dd6d049d0/tqdm-4.32.1-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hCollecting pptk==0.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/01/2c0067e3a54d654e527dfc878d56db0f602fed6b468fec789cf287cf577d/pptk-0.1.0-cp37-none-manylinux1_x86_64.whl (24.8MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8MB 67.4MB/s \n",
            "\u001b[?25hCollecting pillow<7.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/3f/03375124676ab49ca6e6917c0f1f663afb8354d5d24e12f4fe4587a39ae2/Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.0.0->kaolin==0.1.0) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.0.0->kaolin==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.0.0->kaolin==0.1.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.0.0->kaolin==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.0.0->kaolin==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.0.0->kaolin==0.1.0) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.0.0->kaolin==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2->kaolin==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2->kaolin==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2->kaolin==0.1.0) (2.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from trimesh>=3.0->kaolin==0.1.0) (54.1.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image==0.16.2->kaolin==0.1.0) (4.4.2)\n",
            "Building wheels for collected packages: kaolin\n",
            "  Building wheel for kaolin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaolin: filename=kaolin-0.1.0-cp37-cp37m-linux_x86_64.whl size=21189848 sha256=9c178d03e826c2ad8c394880c366f7f4bc37892320131a8f1ad05cef351b2743\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c72gyy69/wheels/f3/bc/2e/b6e313d80983d094d072fcd198f655215207c698ea2a4380ef\n",
            "Successfully built kaolin\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.32.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.2.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.2.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.32.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: matplotlib, trimesh, tqdm, pptk, pillow, kaolin\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed kaolin-0.1.0 matplotlib-2.2.5 pillow-6.2.2 pptk-0.1.0 tqdm-4.32.1 trimesh-3.9.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uul5TJ75gkEA"
      },
      "source": [
        "The installation might take a couple of minutes. After it is done, restart the runtime on Google on Colab. After restarting, Kaolin should be installed correctly.\n",
        "\n",
        "You will also need to the [flownet3d.pytorch](https://github.com/multimodallearning/flownet3d.pytorch) repository, which you can clone:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWrGSwp2gkEB"
      },
      "source": [
        "!git clone https://github.com/multimodallearning/flownet3d.pytorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpLXhpEIgkEB"
      },
      "source": [
        "You can use `gdown` for downloading the [KITTI data](https://drive.google.com/open?id=1XBsF35wKY0rmaL7x7grD_evvKCAccbKi):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnpwLENRgkEB",
        "outputId": "d1066b97-8787-4e41-c29b-3e4abd0ecd81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1XBsF35wKY0rmaL7x7grD_evvKCAccbKi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XBsF35wKY0rmaL7x7grD_evvKCAccbKi\n",
            "To: /content/kitti_rm_ground.tar\n",
            "279MB [00:01, 270MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0sCgU3IgkEC"
      },
      "source": [
        "Now you can try extending and running the code for KITTI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nblAfqm3gkEC",
        "outputId": "616bb779-9db3-41bd-8c5f-481af2ffbc47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Manager\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import kaolin as kal\n",
        "from kaolin.models.PointNet2 import furthest_point_sampling\n",
        "from kaolin.models.PointNet2 import fps_gather_by_index\n",
        "from kaolin.models.PointNet2 import ball_query\n",
        "from kaolin.models.PointNet2 import group_gather_by_index\n",
        "from kaolin.models.PointNet2 import three_nn\n",
        "from kaolin.models.PointNet2 import three_interpolate\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d75c16b008a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkaolin\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaolin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPointNet2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfurthest_point_sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaolin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPointNet2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfps_gather_by_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaolin/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaolin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconversions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaolin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaolin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraphics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaolin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaolin/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodelnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshrec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscannet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# nuscenes-devkit will import matplotlib trying for an x11 backend, workaround here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaolin/datasets/scannet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msvhn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVHN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mphototour\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhotoTour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfakedata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFakeData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msemeion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSEMEION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0momniglot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmniglot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/fakedata.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautoaugment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0maccimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_interpolation_modes_from_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0maccimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_pil\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPILLOW_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misStringType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'isStringType' from 'PIL._util' (/usr/local/lib/python3.7/dist-packages/PIL/_util.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHw-o9MBnkTf",
        "outputId": "90c4ba38-282d-4239-dbee-be0c609eaf99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = 'REPLACE_WITH_YOUR_FILE_ID'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ApiRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchMetadata\u001b[0;34m(self, fields, fetch_all)\u001b[0m\n\u001b[1;32m    236\u001b[0m                                                  fields=fields)\\\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 404 when requesting https://www.googleapis.com/drive/v2/files/REPLACE_WITH_YOUR_FILE_ID?alt=json returned \"File not found: REPLACE_WITH_YOUR_FILE_ID\". Details: \"File not found: REPLACE_WITH_YOUR_FILE_ID\">",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mApiRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ad402f93a98a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'REPLACE_WITH_YOUR_FILE_ID'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloaded content \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentString\u001b[0;34m(self, mimetype, encoding, remove_bom)\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet_Http_Object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchMetadata\u001b[0;34m(self, fields, fetch_all)\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mApiRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mApiRequestError\u001b[0m: <HttpError 404 when requesting https://www.googleapis.com/drive/v2/files/REPLACE_WITH_YOUR_FILE_ID?alt=json returned \"File not found: REPLACE_WITH_YOUR_FILE_ID\". Details: \"File not found: REPLACE_WITH_YOUR_FILE_ID\">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uys2S0oEgkED",
        "outputId": "72703951-5870-4629-e6cd-4540932780b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "class SceneflowDataset(Dataset):\n",
        "    def __init__(self, npoints=2048, root='data/data_processed_maxcut_35_20k_2k_8192', train=True, cache=None):\n",
        "        self.npoints = npoints\n",
        "        self.train = train\n",
        "        self.root = root\n",
        "        if self.train:\n",
        "            self.datapath = glob.glob(os.path.join(self.root, 'TRAIN*.npz'))\n",
        "        else:\n",
        "            self.datapath = glob.glob(os.path.join(self.root, 'TEST*.npz'))\n",
        "        \n",
        "        if cache is None:\n",
        "            self.cache = {}\n",
        "        else:\n",
        "            self.cache = cache\n",
        "        \n",
        "        self.cache_size = 30000\n",
        "\n",
        "        ###### deal with one bad datapoint with nan value\n",
        "        self.datapath = [d for d in self.datapath if 'TRAIN_C_0140_left_0006-0' not in d]\n",
        "        ######\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index in self.cache:\n",
        "            pos1, pos2, color1, color2, flow, mask1 = self.cache[index]\n",
        "        else:\n",
        "            fn = self.datapath[index]\n",
        "            with open(fn, 'rb') as fp:\n",
        "                data = np.load(fp)\n",
        "                pos1 = data['points1'].astype('float32')\n",
        "                pos2 = data['points2'].astype('float32')\n",
        "                color1 = data['color1'].astype('float32') / 255\n",
        "                color2 = data['color2'].astype('float32') / 255\n",
        "                flow = data['flow'].astype('float32')\n",
        "                mask1 = data['valid_mask1']\n",
        "\n",
        "            if len(self.cache) < self.cache_size:\n",
        "                self.cache[index] = (pos1, pos2, color1, color2, flow, mask1)\n",
        "\n",
        "        if self.train:\n",
        "            n1 = pos1.shape[0]\n",
        "            sample_idx1 = np.random.choice(n1, self.npoints, replace=False)\n",
        "            n2 = pos2.shape[0]\n",
        "            sample_idx2 = np.random.choice(n2, self.npoints, replace=False)\n",
        "\n",
        "            pos1 = pos1[sample_idx1, :]\n",
        "            pos2 = pos2[sample_idx2, :]\n",
        "            color1 = color1[sample_idx1, :]\n",
        "            color2 = color2[sample_idx2, :]\n",
        "            flow = flow[sample_idx1, :]\n",
        "            mask1 = mask1[sample_idx1]\n",
        "        else:\n",
        "            pos1 = pos1[:self.npoints, :]\n",
        "            pos2 = pos2[:self.npoints, :]\n",
        "            color1 = color1[:self.npoints, :]\n",
        "            color2 = color2[:self.npoints, :]\n",
        "            flow = flow[:self.npoints, :]\n",
        "            mask1 = mask1[:self.npoints]\n",
        "\n",
        "        pos1_center = np.mean(pos1, 0)\n",
        "        pos1 -= pos1_center\n",
        "        pos2 -= pos1_center\n",
        "        \n",
        "        pos1 = torch.from_numpy(pos1).t()\n",
        "        pos2 = torch.from_numpy(pos2).t()\n",
        "        color1 = torch.from_numpy(color1).t()\n",
        "        color2 = torch.from_numpy(color2).t()\n",
        "        flow = torch.from_numpy(flow).t()\n",
        "        mask1 = torch.from_numpy(mask1)\n",
        "\n",
        "        return pos1, pos2, color1, color2, flow, mask1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datapath)\n",
        "    \n",
        "train_set = SceneflowDataset(train=True)\n",
        "points1, points2, color1, color2, flow, mask1 = train_set[0]\n",
        "\n",
        "print(points1.shape, points1.dtype)\n",
        "print(points2.shape, points2.dtype)\n",
        "print(color1.shape, color1.dtype)\n",
        "print(color2.shape, color2.dtype)\n",
        "print(flow.shape, flow.dtype)\n",
        "print(mask1.shape, mask1.dtype)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fcd7d30ccf09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSceneflowDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mpoints1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-fcd7d30ccf09>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mpos1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsNe5lXugkEE"
      },
      "source": [
        "def set_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "def pdist2squared(x, y):\n",
        "    xx = (x**2).sum(dim=1).unsqueeze(2)\n",
        "    yy = (y**2).sum(dim=1).unsqueeze(1)\n",
        "    dist = xx + yy - 2.0 * torch.bmm(x.permute(0, 2, 1), y)\n",
        "    dist[dist != dist] = 0\n",
        "    dist = torch.clamp(dist, 0.0, np.inf)\n",
        "    return dist\n",
        "\n",
        "def parameter_count(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class ClippedStepLR(optim.lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, step_size, min_lr, gamma=0.1, last_epoch=-1):\n",
        "        self.step_size = step_size\n",
        "        self.min_lr = min_lr\n",
        "        self.gamma = gamma\n",
        "        super(ClippedStepLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [max(base_lr * self.gamma ** (self.last_epoch // self.step_size), self.min_lr)\n",
        "                for base_lr in self.base_lrs]\n",
        "    \n",
        "def criterion(pred_flow, flow, mask):\n",
        "    loss = torch.mean(mask * torch.sum((pred_flow - flow) * (pred_flow - flow), dim=1) / 2.0)\n",
        "    return loss\n",
        "\n",
        "def error(pred, labels, mask):\n",
        "    pred = pred.permute(0,2,1).cpu().numpy()\n",
        "    labels = labels.permute(0,2,1).cpu().numpy()\n",
        "    mask = mask.cpu().numpy()\n",
        "    \n",
        "    err = np.sqrt(np.sum((pred - labels)**2, 2) + 1e-20)\n",
        "\n",
        "    gtflow_len = np.sqrt(np.sum(labels*labels, 2) + 1e-20) # B,N\n",
        "    acc050 = np.sum(np.logical_or((err <= 0.05)*mask, (err/gtflow_len <= 0.05)*mask), axis=1)\n",
        "    acc010 = np.sum(np.logical_or((err <= 0.1)*mask, (err/gtflow_len <= 0.1)*mask), axis=1)\n",
        "\n",
        "    mask_sum = np.sum(mask, 1)\n",
        "    acc050 = acc050[mask_sum > 0] / mask_sum[mask_sum > 0]\n",
        "    acc050 = np.mean(acc050)\n",
        "    acc010 = acc010[mask_sum > 0] / mask_sum[mask_sum > 0]\n",
        "    acc010 = np.mean(acc010)\n",
        "\n",
        "    epe = np.sum(err * mask, 1)[mask_sum > 0] / mask_sum[mask_sum > 0]\n",
        "    epe = np.mean(epe)\n",
        "    return epe, acc050, acc010"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbOmymoJgkEF"
      },
      "source": [
        "class Sample(nn.Module):\n",
        "    def __init__(self, num_points):\n",
        "        super(Sample, self).__init__()\n",
        "        \n",
        "        self.num_points = num_points\n",
        "        \n",
        "    def forward(self, points):\n",
        "        new_points_ind = furthest_point_sampling(points.permute(0, 2, 1).contiguous(), self.num_points)\n",
        "        new_points = fps_gather_by_index(points, new_points_ind)\n",
        "        return new_points\n",
        "    \n",
        "class Group(nn.Module):\n",
        "    def __init__(self, radius, num_samples, knn=False):\n",
        "        super(Group, self).__init__()\n",
        "        \n",
        "        self.radius = radius\n",
        "        self.num_samples = num_samples\n",
        "        self.knn = knn\n",
        "        \n",
        "    def forward(self, points, new_points, features):\n",
        "        if self.knn:\n",
        "            dist = pdist2squared(points, new_points)\n",
        "            ind = dist.topk(self.num_samples, dim=1, largest=False)[1].int().permute(0, 2, 1).contiguous()\n",
        "        else:\n",
        "            ind = ball_query(self.radius, self.num_samples, points.permute(0, 2, 1).contiguous(),\n",
        "                             new_points.permute(0, 2, 1).contiguous(), False)\n",
        "        grouped_points = group_gather_by_index(points, ind)\n",
        "        grouped_points -= new_points.unsqueeze(3)\n",
        "        grouped_features = group_gather_by_index(features, ind)\n",
        "        new_features = torch.cat([grouped_points, grouped_features], dim=1)\n",
        "        return new_features\n",
        "\n",
        "class SetConv(nn.Module):\n",
        "    def __init__(self, num_points, radius, num_samples, in_channels, out_channels):\n",
        "        super(SetConv, self).__init__()\n",
        "        \n",
        "        self.sample = Sample(num_points)\n",
        "        self.group = Group(radius, num_samples)\n",
        "        \n",
        "        layers = []\n",
        "        out_channels = [in_channels+3, *out_channels]\n",
        "        for i in range(1, len(out_channels)):\n",
        "            layers += [nn.Conv2d(out_channels[i - 1], out_channels[i], 1, bias=True), nn.BatchNorm2d(out_channels[i], eps=0.001), nn.ReLU()]\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, points, features):\n",
        "        new_points = self.sample(points)\n",
        "        new_features = self.group(points, new_points, features)\n",
        "        new_features = self.conv(new_features)\n",
        "        new_features = new_features.max(dim=3)[0]\n",
        "        return new_points, new_features\n",
        "    \n",
        "class FlowEmbedding(nn.Module):\n",
        "    def __init__(self, num_samples, in_channels, out_channels):\n",
        "        super(FlowEmbedding, self).__init__()\n",
        "        \n",
        "        self.num_samples = num_samples\n",
        "        \n",
        "        self.group = Group(None, self.num_samples, knn=True)\n",
        "        \n",
        "        layers = []\n",
        "        out_channels = [2*in_channels+3, *out_channels]\n",
        "        for i in range(1, len(out_channels)):\n",
        "            layers += [nn.Conv2d(out_channels[i - 1], out_channels[i], 1, bias=True), nn.BatchNorm2d(out_channels[i], eps=0.001), nn.ReLU()]\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, points1, points2, features1, features2):\n",
        "        new_features = self.group(points2, points1, features2)\n",
        "        new_features = torch.cat([new_features, features1.unsqueeze(3).expand(-1, -1, -1, self.num_samples)], dim=1)\n",
        "        new_features = self.conv(new_features)\n",
        "        new_features = new_features.max(dim=3)[0]\n",
        "        return new_features\n",
        "    \n",
        "class SetUpConv(nn.Module):\n",
        "    def __init__(self, num_samples, in_channels1, in_channels2, out_channels1, out_channels2):\n",
        "        super(SetUpConv, self).__init__()\n",
        "        \n",
        "        self.group = Group(None, num_samples, knn=True)\n",
        "        \n",
        "        layers = []\n",
        "        out_channels1 = [in_channels1+3, *out_channels1]\n",
        "        for i in range(1, len(out_channels1)):\n",
        "            layers += [nn.Conv2d(out_channels1[i - 1], out_channels1[i], 1, bias=True), nn.BatchNorm2d(out_channels1[i], eps=0.001), nn.ReLU()]\n",
        "        self.conv1 = nn.Sequential(*layers)\n",
        "        \n",
        "        layers = []\n",
        "        if len(out_channels1) == 1:\n",
        "            out_channels2 = [in_channels1+in_channels2+3, *out_channels2]\n",
        "        else:\n",
        "            out_channels2 = [out_channels1[-1]+in_channels2, *out_channels2]\n",
        "        for i in range(1, len(out_channels2)):\n",
        "            layers += [nn.Conv2d(out_channels2[i - 1], out_channels2[i], 1, bias=True), nn.BatchNorm2d(out_channels2[i], eps=0.001), nn.ReLU()]\n",
        "        self.conv2 = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, points1, points2, features1, features2):\n",
        "        new_features = self.group(points1, points2, features1)\n",
        "        new_features = self.conv1(new_features)\n",
        "        new_features = new_features.max(dim=3)[0]\n",
        "        new_features = torch.cat([new_features, features2], dim=1)\n",
        "        new_features = new_features.unsqueeze(3)\n",
        "        new_features = self.conv2(new_features)\n",
        "        new_features = new_features.squeeze(3)\n",
        "        return new_features\n",
        "    \n",
        "class FeaturePropagation(nn.Module):\n",
        "    def __init__(self, in_channels1, in_channels2, out_channels):\n",
        "        super(FeaturePropagation, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        out_channels = [in_channels1+in_channels2, *out_channels]\n",
        "        for i in range(1, len(out_channels)):\n",
        "            layers += [nn.Conv2d(out_channels[i - 1], out_channels[i], 1, bias=True), nn.BatchNorm2d(out_channels[i], eps=0.001), nn.ReLU()]\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, points1, points2, features1, features2):\n",
        "        dist, ind = three_nn(points2.permute(0, 2, 1).contiguous(), points1.permute(0, 2, 1).contiguous())\n",
        "        dist = dist * dist\n",
        "        dist[dist < 1e-10] = 1e-10\n",
        "        inverse_dist = 1.0 / dist\n",
        "        norm = torch.sum(inverse_dist, dim=2, keepdim=True)\n",
        "        weights = inverse_dist / norm\n",
        "        #new_features = three_interpolate(features1, ind, weights) # wrong gradients\n",
        "        new_features = torch.sum(group_gather_by_index(features1, ind) * weights.unsqueeze(1), dim = 3)\n",
        "        new_features = torch.cat([new_features, features2], dim=1)\n",
        "        new_features = self.conv(new_features.unsqueeze(3)).squeeze(3)\n",
        "        return new_features\n",
        "\n",
        "class FlowNet3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FlowNet3D, self).__init__()\n",
        "        \n",
        "        self.set_conv1 = SetConv(1024, 0.5, 16, 3, [32, 32, 64])\n",
        "        self.set_conv2 = SetConv(256, 1.0, 16, 64, [64, 64, 128])\n",
        "        self.flow_embedding = FlowEmbedding(64, 128, [128, 128, 128])\n",
        "        self.set_conv3 = SetConv(64, 2.0, 8, 128, [128, 128, 256])\n",
        "        self.set_conv4 = SetConv(16, 4.0, 8, 256, [256, 256, 512])\n",
        "        self.set_upconv1 = SetUpConv(8, 512, 256, [], [256, 256])\n",
        "        self.set_upconv2 = SetUpConv(8, 256, 256, [128, 128, 256], [256])\n",
        "        self.set_upconv3 = SetUpConv(8, 256, 64, [128, 128, 256], [256])\n",
        "        self.fp = FeaturePropagation(256, 3, [256, 256])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv1d(256, 128, 1, bias=True),\n",
        "            nn.BatchNorm1d(128, eps=0.001),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 3, 1, bias=True)\n",
        "        )\n",
        "         \n",
        "    def forward(self, points1, points2, features1, features2):\n",
        "        points1_1, features1_1 = self.set_conv1(points1, features1)\n",
        "        points1_2, features1_2 = self.set_conv2(points1_1, features1_1)\n",
        "\n",
        "        points2_1, features2_1 = self.set_conv1(points2, features2)\n",
        "        points2_2, features2_2 = self.set_conv2(points2_1, features2_1)\n",
        "\n",
        "        embedding = self.flow_embedding(points1_2, points2_2, features1_2, features2_2)\n",
        "        \n",
        "        points1_3, features1_3 = self.set_conv3(points1_2, embedding)\n",
        "        points1_4, features1_4 = self.set_conv4(points1_3, features1_3)\n",
        "        \n",
        "        new_features1_3 = self.set_upconv1(points1_4, points1_3, features1_4, features1_3)\n",
        "        new_features1_2 = self.set_upconv2(points1_3, points1_2, new_features1_3, torch.cat([features1_2, embedding], dim=1))\n",
        "        new_features1_1 = self.set_upconv3(points1_2, points1_1, new_features1_2, features1_1)\n",
        "        new_features1 = self.fp(points1_1, points1, new_features1_1, features1)\n",
        "\n",
        "        flow = self.classifier(new_features1)\n",
        "        \n",
        "        return flow\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieP_5KAEgkEH",
        "outputId": "78362c8a-a7dc-4290-f68b-978068a52ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "tf_path = os.path.abspath('/path/to/model.ckpt')\n",
        "init_vars = tf.train.list_variables(tf_path)\n",
        "tf_vars = {}\n",
        "for name, shape in init_vars:\n",
        "    array = tf.train.load_variable(tf_path, name)\n",
        "    tf_vars[name] = array\n",
        "\n",
        "mapping = {'fa_layer4/conv_0/biases' : 'fp.conv.0.bias',\n",
        "           'fa_layer4/conv_0/weights' : 'fp.conv.0.weight',\n",
        "           'fa_layer4/conv_0/bn/beta' : 'fp.conv.1.bias',\n",
        "           'fa_layer4/conv_0/bn/gamma' : 'fp.conv.1.weight',\n",
        "           'fa_layer4/conv_0/bn/moving_mean' : 'fp.conv.1.running_mean',\n",
        "           'fa_layer4/conv_0/bn/moving_variance' : 'fp.conv.1.running_var',\n",
        "           'fa_layer4/conv_1/biases' : 'fp.conv.3.bias',\n",
        "           'fa_layer4/conv_1/weights' : 'fp.conv.3.weight',\n",
        "           'fa_layer4/conv_1/bn/beta' : 'fp.conv.4.bias',\n",
        "           'fa_layer4/conv_1/bn/gamma' : 'fp.conv.4.weight',\n",
        "           'fa_layer4/conv_1/bn/moving_mean' : 'fp.conv.4.running_mean',\n",
        "           'fa_layer4/conv_1/bn/moving_variance' : 'fp.conv.4.running_var',\n",
        "           'fc1/biases' : 'classifier.0.bias',\n",
        "           'fc1/bn/beta' : 'classifier.1.bias',\n",
        "           'fc1/bn/gamma' : 'classifier.1.weight',\n",
        "           'fc1/bn/moving_mean' : 'classifier.1.running_mean',\n",
        "           'fc1/bn/moving_variance' : 'classifier.1.running_var',\n",
        "           'fc1/weights' : 'classifier.0.weight',\n",
        "           'fc2/biases' : 'classifier.3.bias',\n",
        "           'fc2/weights' : 'classifier.3.weight',\n",
        "           'flow_embedding/conv_diff_0/biases' : 'flow_embedding.conv.0.bias',\n",
        "           'flow_embedding/conv_diff_0/bn/beta' : 'flow_embedding.conv.1.bias',\n",
        "           'flow_embedding/conv_diff_0/bn/gamma' : 'flow_embedding.conv.1.weight',\n",
        "           'flow_embedding/conv_diff_0/bn/moving_mean' : 'flow_embedding.conv.1.running_mean',\n",
        "           'flow_embedding/conv_diff_0/bn/moving_variance' : 'flow_embedding.conv.1.running_var',\n",
        "           'flow_embedding/conv_diff_0/weights' : 'flow_embedding.conv.0.weight',\n",
        "           'flow_embedding/conv_diff_1/biases' : 'flow_embedding.conv.3.bias',\n",
        "           'flow_embedding/conv_diff_1/bn/beta' : 'flow_embedding.conv.4.bias',\n",
        "           'flow_embedding/conv_diff_1/bn/gamma' : 'flow_embedding.conv.4.weight',\n",
        "           'flow_embedding/conv_diff_1/bn/moving_mean' : 'flow_embedding.conv.4.running_mean',\n",
        "           'flow_embedding/conv_diff_1/bn/moving_variance' : 'flow_embedding.conv.4.running_var',\n",
        "           'flow_embedding/conv_diff_1/weights' : 'flow_embedding.conv.3.weight',\n",
        "           'flow_embedding/conv_diff_2/biases' : 'flow_embedding.conv.6.bias',\n",
        "           'flow_embedding/conv_diff_2/bn/beta' : 'flow_embedding.conv.7.bias',\n",
        "           'flow_embedding/conv_diff_2/bn/gamma' : 'flow_embedding.conv.7.weight',\n",
        "           'flow_embedding/conv_diff_2/bn/moving_mean' : 'flow_embedding.conv.7.running_mean',\n",
        "           'flow_embedding/conv_diff_2/bn/moving_variance' : 'flow_embedding.conv.7.running_var',\n",
        "           'flow_embedding/conv_diff_2/weights' : 'flow_embedding.conv.6.weight',\n",
        "           'layer3/conv0/biases' : 'set_conv3.conv.0.bias',\n",
        "           'layer3/conv0/bn/beta' : 'set_conv3.conv.1.bias',\n",
        "           'layer3/conv0/bn/gamma' : 'set_conv3.conv.1.weight',\n",
        "           'layer3/conv0/bn/moving_mean' : 'set_conv3.conv.1.running_mean',\n",
        "           'layer3/conv0/bn/moving_variance' : 'set_conv3.conv.1.running_var',\n",
        "           'layer3/conv0/weights' : 'set_conv3.conv.0.weight',\n",
        "           'layer3/conv1/biases' : 'set_conv3.conv.3.bias',\n",
        "           'layer3/conv1/bn/beta' : 'set_conv3.conv.4.bias',\n",
        "           'layer3/conv1/bn/gamma' : 'set_conv3.conv.4.weight',\n",
        "           'layer3/conv1/bn/moving_mean' : 'set_conv3.conv.4.running_mean',\n",
        "           'layer3/conv1/bn/moving_variance' : 'set_conv3.conv.4.running_var',\n",
        "           'layer3/conv1/weights' : 'set_conv3.conv.3.weight',\n",
        "           'layer3/conv2/biases' : 'set_conv3.conv.6.bias',\n",
        "           'layer3/conv2/bn/beta' : 'set_conv3.conv.7.bias',\n",
        "           'layer3/conv2/bn/gamma' : 'set_conv3.conv.7.weight',\n",
        "           'layer3/conv2/bn/moving_mean' : 'set_conv3.conv.7.running_mean',\n",
        "           'layer3/conv2/bn/moving_variance' : 'set_conv3.conv.7.running_var',\n",
        "           'layer3/conv2/weights' : 'set_conv3.conv.6.weight',\n",
        "           'layer4/conv0/biases' : 'set_conv4.conv.0.bias',\n",
        "           'layer4/conv0/bn/beta' : 'set_conv4.conv.1.bias',\n",
        "           'layer4/conv0/bn/gamma' : 'set_conv4.conv.1.weight',\n",
        "           'layer4/conv0/bn/moving_mean' : 'set_conv4.conv.1.running_mean',\n",
        "           'layer4/conv0/bn/moving_variance' : 'set_conv4.conv.1.running_var',\n",
        "           'layer4/conv0/weights' : 'set_conv4.conv.0.weight',\n",
        "           'layer4/conv1/biases' : 'set_conv4.conv.3.bias',\n",
        "           'layer4/conv1/bn/beta' : 'set_conv4.conv.4.bias',\n",
        "           'layer4/conv1/bn/gamma' : 'set_conv4.conv.4.weight',\n",
        "           'layer4/conv1/bn/moving_mean' : 'set_conv4.conv.4.running_mean',\n",
        "           'layer4/conv1/bn/moving_variance' : 'set_conv4.conv.4.running_var',\n",
        "           'layer4/conv1/weights' : 'set_conv4.conv.3.weight',\n",
        "           'layer4/conv2/biases' : 'set_conv4.conv.6.bias',\n",
        "           'layer4/conv2/bn/beta' : 'set_conv4.conv.7.bias',\n",
        "           'layer4/conv2/bn/gamma' : 'set_conv4.conv.7.weight',\n",
        "           'layer4/conv2/bn/moving_mean' : 'set_conv4.conv.7.running_mean',\n",
        "           'layer4/conv2/bn/moving_variance' : 'set_conv4.conv.7.running_var',\n",
        "           'layer4/conv2/weights' : 'set_conv4.conv.6.weight',\n",
        "           'sa1/layer1/conv0/biases' : 'set_conv1.conv.0.bias',\n",
        "           'sa1/layer1/conv0/bn/beta' : 'set_conv1.conv.1.bias',\n",
        "           'sa1/layer1/conv0/bn/gamma' : 'set_conv1.conv.1.weight',\n",
        "           'sa1/layer1/conv0/bn/moving_mean' : 'set_conv1.conv.1.running_mean',\n",
        "           'sa1/layer1/conv0/bn/moving_variance' : 'set_conv1.conv.1.running_var',\n",
        "           'sa1/layer1/conv0/weights' : 'set_conv1.conv.0.weight',\n",
        "           'sa1/layer1/conv1/biases' : 'set_conv1.conv.3.bias',\n",
        "           'sa1/layer1/conv1/bn/beta' : 'set_conv1.conv.4.bias',\n",
        "           'sa1/layer1/conv1/bn/gamma' : 'set_conv1.conv.4.weight',\n",
        "           'sa1/layer1/conv1/bn/moving_mean' : 'set_conv1.conv.4.running_mean',\n",
        "           'sa1/layer1/conv1/bn/moving_variance' : 'set_conv1.conv.4.running_var',\n",
        "           'sa1/layer1/conv1/weights' : 'set_conv1.conv.3.weight',\n",
        "           'sa1/layer1/conv2/biases' : 'set_conv1.conv.6.bias',\n",
        "           'sa1/layer1/conv2/bn/beta' : 'set_conv1.conv.7.bias',\n",
        "           'sa1/layer1/conv2/bn/gamma' : 'set_conv1.conv.7.weight',\n",
        "           'sa1/layer1/conv2/bn/moving_mean' : 'set_conv1.conv.7.running_mean',\n",
        "           'sa1/layer1/conv2/bn/moving_variance' : 'set_conv1.conv.7.running_var',\n",
        "           'sa1/layer1/conv2/weights' : 'set_conv1.conv.6.weight',\n",
        "           'sa1/layer2/conv0/biases' : 'set_conv2.conv.0.bias',\n",
        "           'sa1/layer2/conv0/bn/beta' : 'set_conv2.conv.1.bias',\n",
        "           'sa1/layer2/conv0/bn/gamma' : 'set_conv2.conv.1.weight',\n",
        "           'sa1/layer2/conv0/bn/moving_mean' : 'set_conv2.conv.1.running_mean',\n",
        "           'sa1/layer2/conv0/bn/moving_variance' : 'set_conv2.conv.1.running_var',\n",
        "           'sa1/layer2/conv0/weights' : 'set_conv2.conv.0.weight',\n",
        "           'sa1/layer2/conv1/biases' : 'set_conv2.conv.3.bias',\n",
        "           'sa1/layer2/conv1/bn/beta' : 'set_conv2.conv.4.bias',\n",
        "           'sa1/layer2/conv1/bn/gamma' : 'set_conv2.conv.4.weight',\n",
        "           'sa1/layer2/conv1/bn/moving_mean' : 'set_conv2.conv.4.running_mean',\n",
        "           'sa1/layer2/conv1/bn/moving_variance' : 'set_conv2.conv.4.running_var',\n",
        "           'sa1/layer2/conv1/weights' : 'set_conv2.conv.3.weight',\n",
        "           'sa1/layer2/conv2/biases' : 'set_conv2.conv.6.bias',\n",
        "           'sa1/layer2/conv2/bn/beta' : 'set_conv2.conv.7.bias',\n",
        "           'sa1/layer2/conv2/bn/gamma' : 'set_conv2.conv.7.weight',\n",
        "           'sa1/layer2/conv2/bn/moving_mean' : 'set_conv2.conv.7.running_mean',\n",
        "           'sa1/layer2/conv2/bn/moving_variance' : 'set_conv2.conv.7.running_var',\n",
        "           'sa1/layer2/conv2/weights' : 'set_conv2.conv.6.weight',\n",
        "           'up_sa_layer1/post-conv0/biases' : 'set_upconv1.conv2.0.bias',\n",
        "           'up_sa_layer1/post-conv0/bn/beta' : 'set_upconv1.conv2.1.bias',\n",
        "           'up_sa_layer1/post-conv0/bn/gamma' : 'set_upconv1.conv2.1.weight',\n",
        "           'up_sa_layer1/post-conv0/bn/moving_mean' : 'set_upconv1.conv2.1.running_mean',\n",
        "           'up_sa_layer1/post-conv0/bn/moving_variance' : 'set_upconv1.conv2.1.running_var',\n",
        "           'up_sa_layer1/post-conv0/weights' : 'set_upconv1.conv2.0.weight',\n",
        "           'up_sa_layer1/post-conv1/biases' : 'set_upconv1.conv2.3.bias',\n",
        "           'up_sa_layer1/post-conv1/bn/beta' : 'set_upconv1.conv2.4.bias',\n",
        "           'up_sa_layer1/post-conv1/bn/gamma' : 'set_upconv1.conv2.4.weight',\n",
        "           'up_sa_layer1/post-conv1/bn/moving_mean' : 'set_upconv1.conv2.4.running_mean',\n",
        "           'up_sa_layer1/post-conv1/bn/moving_variance' : 'set_upconv1.conv2.4.running_var',\n",
        "           'up_sa_layer1/post-conv1/weights' : 'set_upconv1.conv2.3.weight',\n",
        "           'up_sa_layer2/conv0/biases' : 'set_upconv2.conv1.0.bias',\n",
        "           'up_sa_layer2/conv0/bn/beta' : 'set_upconv2.conv1.1.bias',\n",
        "           'up_sa_layer2/conv0/bn/gamma' : 'set_upconv2.conv1.1.weight',\n",
        "           'up_sa_layer2/conv0/bn/moving_mean' : 'set_upconv2.conv1.1.running_mean',\n",
        "           'up_sa_layer2/conv0/bn/moving_variance' : 'set_upconv2.conv1.1.running_var',\n",
        "           'up_sa_layer2/conv0/weights' : 'set_upconv2.conv1.0.weight',\n",
        "           'up_sa_layer2/conv1/biases' : 'set_upconv2.conv1.3.bias',\n",
        "           'up_sa_layer2/conv1/bn/beta' : 'set_upconv2.conv1.4.bias',\n",
        "           'up_sa_layer2/conv1/bn/gamma' : 'set_upconv2.conv1.4.weight',\n",
        "           'up_sa_layer2/conv1/bn/moving_mean' : 'set_upconv2.conv1.4.running_mean',\n",
        "           'up_sa_layer2/conv1/bn/moving_variance' : 'set_upconv2.conv1.4.running_var',\n",
        "           'up_sa_layer2/conv1/weights' : 'set_upconv2.conv1.3.weight',\n",
        "           'up_sa_layer2/conv2/biases' : 'set_upconv2.conv1.6.bias',\n",
        "           'up_sa_layer2/conv2/bn/beta' : 'set_upconv2.conv1.7.bias',\n",
        "           'up_sa_layer2/conv2/bn/gamma' : 'set_upconv2.conv1.7.weight',\n",
        "           'up_sa_layer2/conv2/bn/moving_mean' : 'set_upconv2.conv1.7.running_mean',\n",
        "           'up_sa_layer2/conv2/bn/moving_variance' : 'set_upconv2.conv1.7.running_var',\n",
        "           'up_sa_layer2/conv2/weights' : 'set_upconv2.conv1.6.weight',\n",
        "           'up_sa_layer2/post-conv0/biases' : 'set_upconv2.conv2.0.bias',\n",
        "           'up_sa_layer2/post-conv0/bn/beta' : 'set_upconv2.conv2.1.bias',\n",
        "           'up_sa_layer2/post-conv0/bn/gamma' : 'set_upconv2.conv2.1.weight',\n",
        "           'up_sa_layer2/post-conv0/bn/moving_mean' : 'set_upconv2.conv2.1.running_mean',\n",
        "           'up_sa_layer2/post-conv0/bn/moving_variance' : 'set_upconv2.conv2.1.running_var',\n",
        "           'up_sa_layer2/post-conv0/weights' : 'set_upconv2.conv2.0.weight',\n",
        "           'up_sa_layer3/conv0/biases' : 'set_upconv3.conv1.0.bias',\n",
        "           'up_sa_layer3/conv0/bn/beta' : 'set_upconv3.conv1.1.bias',\n",
        "           'up_sa_layer3/conv0/bn/gamma' : 'set_upconv3.conv1.1.weight',\n",
        "           'up_sa_layer3/conv0/bn/moving_mean' : 'set_upconv3.conv1.1.running_mean',\n",
        "           'up_sa_layer3/conv0/bn/moving_variance' : 'set_upconv3.conv1.1.running_var',\n",
        "           'up_sa_layer3/conv0/weights' : 'set_upconv3.conv1.0.weight',\n",
        "           'up_sa_layer3/conv1/biases' : 'set_upconv3.conv1.3.bias',\n",
        "           'up_sa_layer3/conv1/bn/beta' : 'set_upconv3.conv1.4.bias',\n",
        "           'up_sa_layer3/conv1/bn/gamma' : 'set_upconv3.conv1.4.weight',\n",
        "           'up_sa_layer3/conv1/bn/moving_mean' : 'set_upconv3.conv1.4.running_mean',\n",
        "           'up_sa_layer3/conv1/bn/moving_variance' : 'set_upconv3.conv1.4.running_var',\n",
        "           'up_sa_layer3/conv1/weights' : 'set_upconv3.conv1.3.weight',\n",
        "           'up_sa_layer3/conv2/biases' : 'set_upconv3.conv1.6.bias',\n",
        "           'up_sa_layer3/conv2/bn/beta' : 'set_upconv3.conv1.7.bias',\n",
        "           'up_sa_layer3/conv2/bn/gamma' : 'set_upconv3.conv1.7.weight',\n",
        "           'up_sa_layer3/conv2/bn/moving_mean' : 'set_upconv3.conv1.7.running_mean',\n",
        "           'up_sa_layer3/conv2/bn/moving_variance' : 'set_upconv3.conv1.7.running_var',\n",
        "           'up_sa_layer3/conv2/weights' : 'set_upconv3.conv1.6.weight',\n",
        "           'up_sa_layer3/post-conv0/biases' : 'set_upconv3.conv2.0.bias',\n",
        "           'up_sa_layer3/post-conv0/bn/beta' : 'set_upconv3.conv2.1.bias',\n",
        "           'up_sa_layer3/post-conv0/bn/gamma' : 'set_upconv3.conv2.1.weight',\n",
        "           'up_sa_layer3/post-conv0/bn/moving_mean' : 'set_upconv3.conv2.1.running_mean',\n",
        "           'up_sa_layer3/post-conv0/bn/moving_variance' : 'set_upconv3.conv2.1.running_var',\n",
        "           'up_sa_layer3/post-conv0/weights' : 'set_upconv3.conv2.0.weight',\n",
        "          }\n",
        "mapping=dict([reversed(i) for i in mapping.items()])\n",
        "\n",
        "state_dict = FlowNet3D().state_dict()\n",
        "for key, _ in state_dict.items():\n",
        "    if not state_dict[key].shape:\n",
        "        continue\n",
        "    elif len(state_dict[key].shape) == 4:\n",
        "        state_dict[key][:, :, :, :] = torch.from_numpy(tf_vars[mapping[key]]).permute(3, 2, 0, 1)\n",
        "        if 'flow_embedding.conv.0' in key:\n",
        "            temp = state_dict[key][:, -3:, :, :].clone()\n",
        "            state_dict[key][:, 3:, :, :] = state_dict[key][:, :-3, :, :].clone()\n",
        "            state_dict[key][:, :3, :, :] = temp\n",
        "        if 'set_upconv1.conv2.0' in key:\n",
        "            temp = state_dict[key][:, 512:515, :, :].clone()\n",
        "            state_dict[key][:, 3:515, :, :] = state_dict[key][:, :512, :, :].clone()\n",
        "            state_dict[key][:, :3, :, :] = temp\n",
        "        if 'set_upconv2.conv1.0' in key:\n",
        "            temp = state_dict[key][:, 256:259, :, :].clone()\n",
        "            state_dict[key][:, 3:259, :, :] = state_dict[key][:, :256, :, :].clone()\n",
        "            state_dict[key][:, :3, :, :] = temp\n",
        "        if 'set_upconv3.conv1.0' in key:\n",
        "            temp = state_dict[key][:, 256:259, :, :].clone()\n",
        "            state_dict[key][:, 3:259, :, :] = state_dict[key][:, :256, :, :].clone()\n",
        "            state_dict[key][:, :3, :, :] = temp\n",
        "    elif len(state_dict[key].shape) == 3:\n",
        "        state_dict[key][:, :, :] = torch.from_numpy(tf_vars[mapping[key]]).permute(2, 1, 0)\n",
        "    elif len(state_dict[key].shape) == 1:\n",
        "        state_dict[key][:] = torch.from_numpy(tf_vars[mapping[key]])\n",
        "           \n",
        "torch.save(state_dict, 'models/net_tf.pth')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4902e9d5eb48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/path/to/model.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minit_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtf_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minit_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAz15FzggkEI",
        "outputId": "1641cd25-6dab-495f-ba9e-3297205c1ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# data\n",
        "test_set = SceneflowDataset(train=False)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         batch_size=16,\n",
        "                         num_workers=4,\n",
        "                         pin_memory=True,\n",
        "                         drop_last=True)\n",
        "\n",
        "print('test set:', len(test_set), 'samples /', len(test_loader), 'mini-batches')\n",
        "\n",
        "# model\n",
        "net = FlowNet3D().cuda()\n",
        "net.load_state_dict(torch.load('models/net_tf.pth'))\n",
        "net.eval()\n",
        "\n",
        "# statistics\n",
        "loss_sum = 0\n",
        "epe_sum = 0\n",
        "acc050_sum = 0\n",
        "acc010_sum = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # for each mini-batch\n",
        "    for points1, points2, features1, features2, flow, mask1 in test_loader:\n",
        "            \n",
        "        # to GPU\n",
        "        points1 = points1.cuda(non_blocking=True)\n",
        "        points2 = points2.cuda(non_blocking=True)\n",
        "        features1 = features1.cuda(non_blocking=True)\n",
        "        features2 = features2.cuda(non_blocking=True)\n",
        "        flow = flow.cuda(non_blocking=True)\n",
        "        mask1 = mask1.cuda(non_blocking=True)\n",
        "    \n",
        "        pred_flow_sum = torch.zeros(16, 3, 2048).cuda(non_blocking=True)\n",
        "        \n",
        "        # resample 10 times\n",
        "        for i in range(10):\n",
        "            \n",
        "            perm = torch.randperm(points1.shape[2])\n",
        "            points1_perm = points1[:, :, perm]\n",
        "            points2_perm = points2[:, :, perm]\n",
        "            features1_perm = features1[:, :, perm]\n",
        "            features2_perm = features2[:, :, perm]\n",
        "\n",
        "            # forward\n",
        "            pred_flow = net(points1_perm, points2_perm, features1_perm, features2_perm)\n",
        "            pred_flow_sum[:, :, perm] += pred_flow\n",
        "            pred_flow_sum=pred_flow_sum\n",
        "        \n",
        "        # statistics\n",
        "        pred_flow_sum /= 10\n",
        "        loss = criterion(pred_flow_sum, flow, mask1)\n",
        "        loss_sum += loss.item()\n",
        "        epe, acc050, acc010 = error(pred_flow_sum, flow, mask1)\n",
        "        epe_sum += epe\n",
        "        acc050_sum += acc050\n",
        "        acc010_sum += acc010\n",
        "        \n",
        "print('mean loss:', loss_sum/len(test_loader))\n",
        "print('mean epe:', epe_sum/len(test_loader))\n",
        "print('mean acc050:', acc050_sum/len(test_loader))\n",
        "print('mean acc010:', acc010_sum/len(test_loader))\n",
        "    \n",
        "print('---')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test set: 0 samples / 0 mini-batches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9d064b142d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n# data\\ntest_set = SceneflowDataset(train=False)\\ntest_loader = DataLoader(test_set,\\n                         batch_size=16,\\n                         num_workers=4,\\n                         pin_memory=True,\\n                         drop_last=True)\\n\\nprint('test set:', len(test_set), 'samples /', len(test_loader), 'mini-batches')\\n\\n# model\\nnet = FlowNet3D().cuda()\\nnet.load_state_dict(torch.load('models/net_tf.pth'))\\nnet.eval()\\n\\n# statistics\\nloss_sum = 0\\nepe_sum = 0\\nacc050_sum = 0\\nacc010_sum = 0\\n\\nwith torch.no_grad():\\n    \\n    # for each mini-batch\\n    for points1, points2, features1, features2, flow, mask1 in test_loader:\\n            \\n        # to GPU\\n        points1 = points1.cuda(non_blocking=True)\\n        points2 = points2.cuda(non_blocking=True)\\n        features1 = features1.cuda(non_blocking=True)\\n        features2 = features2.cuda(non_blocking=True)\\n        flow = flow.cuda(non_blocking=True)\\n        mask1 = mask1.cuda(non_blocking=True)\\n    \\n        pred_flow_sum = torch.zeros(16, 3, 2048).cuda(non_blocking=True)\\n        \\n        # resample 10 times\\n        for i in range(10):\\n            \\n            perm = torch.randperm(points1.shape[2])\\n            points1_perm = points1[:, :, perm]\\n            points2_perm = points2[:, :, perm]\\n            features1_p...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/net_tf.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr5mmNVNgkEI",
        "outputId": "286b2744-4cd5-4c06-ad13-1a81b46e3584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# parameters\n",
        "BATCH_SIZE = 16\n",
        "NUM_POINTS = 2048\n",
        "NUM_EPOCHS = 150\n",
        "INIT_LR = 0.001\n",
        "MIN_LR = 0.00001\n",
        "STEP_SIZE_LR = 10\n",
        "GAMMA_LR = 0.7\n",
        "INIT_BN_MOMENTUM = 0.5\n",
        "MIN_BN_MOMENTUM = 0.01\n",
        "STEP_SIZE_BN_MOMENTUM = 10\n",
        "GAMMA_BN_MOMENTUM = 0.5\n",
        "\n",
        "# data\n",
        "train_manager = Manager()\n",
        "train_cache = train_manager.dict()\n",
        "train_dataset = SceneflowDataset(npoints=NUM_POINTS, train=True, cache=train_cache)\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          shuffle=True,\n",
        "                          pin_memory=True,\n",
        "                          drop_last=True)\n",
        "print('train:', len(train_dataset), '/', len(train_loader))\n",
        "\n",
        "test_manager = Manager()\n",
        "test_cache = test_manager.dict()\n",
        "test_dataset = SceneflowDataset(npoints=NUM_POINTS, train=False, cache=test_cache)\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        num_workers=4,\n",
        "                        pin_memory=True,\n",
        "                        drop_last=True)\n",
        "print('test:', len(test_dataset), '/', len(test_loader))\n",
        "\n",
        "# net\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.0)\n",
        "    elif isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.BatchNorm2d):\n",
        "        m.weight.data.fill_(1.0)\n",
        "        m.bias.data.fill_(0.0)\n",
        "\n",
        "net = FlowNet3D().cuda()\n",
        "net.apply(init_weights)\n",
        "print('# parameters: ', parameter_count(net))\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=INIT_LR)\n",
        "\n",
        "# learning rate scheduler\n",
        "lr_scheduler = ClippedStepLR(optimizer, STEP_SIZE_LR, MIN_LR, GAMMA_LR)\n",
        "\n",
        "# batch norm momentum scheduler\n",
        "def update_bn_momentum(epoch):\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.BatchNorm2d):\n",
        "            m.momentum = max(INIT_BN_MOMENTUM * GAMMA_BN_MOMENTUM ** (epoch // STEP_SIZE_BN_MOMENTUM), MIN_BN_MOMENTUM)\n",
        "\n",
        "# statistics\n",
        "losses_train = []\n",
        "losses_test = []\n",
        "\n",
        "# for num_epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "    # update batch norm momentum\n",
        "    update_bn_momentum(epoch)\n",
        "    \n",
        "    # train mode\n",
        "    net.train()\n",
        "    \n",
        "    # statistics\n",
        "    running_loss = 0.0\n",
        "    torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # for each mini-batch\n",
        "    for points1, points2, features1, features2, flow, mask1 in train_loader:\n",
        "        # to GPU\n",
        "        points1 = points1.cuda(non_blocking=True)\n",
        "        points2 = points2.cuda(non_blocking=True)\n",
        "        features1 = features1.cuda(non_blocking=True)\n",
        "        features2 = features2.cuda(non_blocking=True)\n",
        "        flow = flow.cuda(non_blocking=True)\n",
        "        mask1 = mask1.cuda(non_blocking=True)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        pred_flow = net(points1, points2, features1, features2)\n",
        "        loss = criterion(pred_flow, flow, mask1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # statistics\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "    \n",
        "    running_loss /= (len(train_loader))\n",
        "    \n",
        "    losses_train.append(running_loss)\n",
        "    \n",
        "    # output\n",
        "    print('Epoch {} (train) -- loss: {:.6f} -- duration (epoch/iteration): {:.4f} min/{:.4f} sec'.format(epoch, running_loss, (end_time-start_time)/60.0, (end_time-start_time)/len(train_loader)))\n",
        "    \n",
        "    # validate\n",
        "    with torch.no_grad():\n",
        "      \n",
        "        # eval mode\n",
        "        net.eval()\n",
        "\n",
        "        # statistics\n",
        "        running_loss = 0.0\n",
        "        torch.cuda.synchronize()\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # for each mini-batch\n",
        "        for points1, points2, features1, features2, flow, mask1 in test_loader:\n",
        "            \n",
        "            # to GPU\n",
        "            points1 = points1.cuda(non_blocking=True)\n",
        "            points2 = points2.cuda(non_blocking=True)\n",
        "            features1 = features1.cuda(non_blocking=True)\n",
        "            features2 = features2.cuda(non_blocking=True)\n",
        "            flow = flow.cuda(non_blocking=True)\n",
        "            mask1 = mask1.cuda(non_blocking=True)\n",
        "\n",
        "            # forward\n",
        "            pred_flow = net(points1, points2, features1, features2)\n",
        "            loss = criterion(pred_flow, flow, mask1)\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "        torch.cuda.synchronize()\n",
        "        end_time = time.time()\n",
        "\n",
        "        running_loss /= len(test_loader)\n",
        "\n",
        "        losses_test.append(running_loss)\n",
        "\n",
        "        # output\n",
        "        print('Epoch {} (test) -- loss: {:.6f} -- duration (epoch/iteration): {:.4f} min/{:.4f} sec'.format(epoch, running_loss, (end_time-start_time)/60.0, (end_time-start_time)/len(train_loader)))\n",
        "        \n",
        "    # update learning rate\n",
        "    lr_scheduler.step()\n",
        "    \n",
        "    print('---')\n",
        "    \n",
        "plt.plot(losses_train)\n",
        "plt.plot(losses_test)\n",
        "\n",
        "net = net.cpu()\n",
        "torch.save(net.state_dict(),'models/net.pth')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-bc7fa3864bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                           \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                           drop_last=True)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;31m# Cannot statically verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m--> 104\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLUMI5vVgkEJ",
        "outputId": "87af5173-9ce9-49c0-8c6e-de489be1bb7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# data\n",
        "test_set = SceneflowDataset(train=False)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         batch_size=16,\n",
        "                         num_workers=4,\n",
        "                         pin_memory=True,\n",
        "                         drop_last=True)\n",
        "\n",
        "print('test set:', len(test_set), 'samples /', len(test_loader), 'mini-batches')\n",
        "\n",
        "# model\n",
        "net = FlowNet3D().cuda()\n",
        "net.load_state_dict(torch.load('models/net.pth'))\n",
        "net.eval()\n",
        "\n",
        "# statistics\n",
        "loss_sum = 0\n",
        "epe_sum = 0\n",
        "acc050_sum = 0\n",
        "acc010_sum = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # for each mini-batch\n",
        "    for points1, points2, features1, features2, flow, mask1 in test_loader:\n",
        "            \n",
        "        # to GPU\n",
        "        points1 = points1.cuda(non_blocking=True)\n",
        "        points2 = points2.cuda(non_blocking=True)\n",
        "        features1 = features1.cuda(non_blocking=True)\n",
        "        features2 = features2.cuda(non_blocking=True)\n",
        "        flow = flow.cuda(non_blocking=True)\n",
        "        mask1 = mask1.cuda(non_blocking=True)\n",
        "    \n",
        "        pred_flow_sum = torch.zeros(16, 3, 2048).cuda(non_blocking=True)\n",
        "        \n",
        "        # resample 10 times\n",
        "        for i in range(10):\n",
        "            \n",
        "            perm = torch.randperm(points1.shape[2])\n",
        "            points1_perm = points1[:, :, perm]\n",
        "            points2_perm = points2[:, :, perm]\n",
        "            features1_perm = features1[:, :, perm]\n",
        "            features2_perm = features2[:, :, perm]\n",
        "\n",
        "            # forward\n",
        "            pred_flow = net(points1_perm, points2_perm, features1_perm, features2_perm)\n",
        "            pred_flow_sum[:, :, perm] += pred_flow\n",
        "        \n",
        "        # statistics\n",
        "        pred_flow_sum /= 10\n",
        "        loss = criterion(pred_flow_sum, flow, mask1)\n",
        "        loss_sum += loss.item()\n",
        "        epe, acc050, acc010 = error(pred_flow_sum, flow, mask1)\n",
        "        epe_sum += epe\n",
        "        acc050_sum += acc050\n",
        "        acc010_sum += acc010\n",
        "        \n",
        "print('mean loss:', loss_sum/len(test_loader))\n",
        "print('mean epe:', epe_sum/len(test_loader))\n",
        "print('mean acc050:', acc050_sum/len(test_loader))\n",
        "print('mean acc010:', acc010_sum/len(test_loader))\n",
        "    \n",
        "print('---')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test set: 0 samples / 0 mini-batches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0980220ea7ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n# data\\ntest_set = SceneflowDataset(train=False)\\ntest_loader = DataLoader(test_set,\\n                         batch_size=16,\\n                         num_workers=4,\\n                         pin_memory=True,\\n                         drop_last=True)\\n\\nprint('test set:', len(test_set), 'samples /', len(test_loader), 'mini-batches')\\n\\n# model\\nnet = FlowNet3D().cuda()\\nnet.load_state_dict(torch.load('models/net.pth'))\\nnet.eval()\\n\\n# statistics\\nloss_sum = 0\\nepe_sum = 0\\nacc050_sum = 0\\nacc010_sum = 0\\n\\nwith torch.no_grad():\\n    \\n    # for each mini-batch\\n    for points1, points2, features1, features2, flow, mask1 in test_loader:\\n            \\n        # to GPU\\n        points1 = points1.cuda(non_blocking=True)\\n        points2 = points2.cuda(non_blocking=True)\\n        features1 = features1.cuda(non_blocking=True)\\n        features2 = features2.cuda(non_blocking=True)\\n        flow = flow.cuda(non_blocking=True)\\n        mask1 = mask1.cuda(non_blocking=True)\\n    \\n        pred_flow_sum = torch.zeros(16, 3, 2048).cuda(non_blocking=True)\\n        \\n        # resample 10 times\\n        for i in range(10):\\n            \\n            perm = torch.randperm(points1.shape[2])\\n            points1_perm = points1[:, :, perm]\\n            points2_perm = points2[:, :, perm]\\n            features1_perm...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/net.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwuBQVROgkEJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}